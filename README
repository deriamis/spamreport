ABOUT

    This build system produces a 'fatpacked' Perl script that, with some file
    assets for geolocation purposes, is useful for reporting on and
    investigating sources of spam and of other anomalous email usage.

    spamreport's documentation is in spamreport --man; briefer information is
    in spamreport --help.

BUILDING (for the first time ever)

    make          # this may work for a bit and then fail
    make depend
    make

BUILDING

    make

(RE)BUILDING

    If only the existing SpamReport modules are changed, 'make' is enough
    to rebuild build/spamreport.  If modules have changed, you may need to edit
    cpanfile and then run 'make distclean' before running 'make', to get the
    new dependencies.

DISTRIBUTION

    The following files in build/ must exist in /root/bin:

        spamreport
        ipscountry.dat
        ip.gif
        cc.gif

    You can then run spamreport as normal.  It will create files under
    /opt/hgmods/logs , and will create this directory if necessary.  If --dump is
    provided, spamreport will check to ensure that the destination is
    reasonable (it exists; it's owned by root), but will otherwise place mode-0600
    files where requested.

    NB. you can run spamreport from anywhere, but those assets must be in
    /root/bin .

USAGE

    See: spamreport --help

ALTERNATE USAGE

    spamreport tries to behave in a eigshell-appropriate way if $RUSER is
    unset.  (Presently this only means that some messages are suppressed.)

    spamreport duplicates ecpp's flags, behavior, and usage if $0 is 'ec'

CACHE

    spamreport preparses exim_mainlog and stores meaningful records in a very
    easily re-parsed form (unpack is all that's required) in compressed files
    that are named after the day of the corresponding logs.  So, 2016-03-25
    logs will all wind up in 2016-03-25.gz , with metadata in 2016-03-25.stor
    files.  Presently, preparsed logs that are definitely complete are reused
    and partial or missing preparsed logs are regenerated on demand.  Presently,
    cache is *only* updated when the required logs are missing or when spamreport
    is invoked with

        spamreport --cron

    The expectation is that this command will be in a cronjob that will run
    once an hour, and that normal report runs, by users, will never actually
    need to parse the exim log themselves (unless they request times that don't
    have cache files).

    The preparsing is very parsimonious with memory, using never more than 30MB
    or so of RSS even when working with 4GB log files.  Report runs can retain a
    bit of analytical data but should still top out at only a few hundred
    megabytes for reports involving several millions of emails.

    Preparsing and reporting are also reasonably quick.  The first ever run on
    a reseller with 4GB logs may take 7 minutes or so, but every subsequent run
    can take advantage of the previous days' cache and may only run in 30
    seconds, down from 7 minutes.  Most cron runs will seek() to the position
    the previous cron stopped at.

FILES

    YYYY-MM-DD.gz - a gzipped preparsed log of exim data from the given date.
        The format is line-based, with each line containing NUL-separated fields,
        without explicit keys.  The first field is the Class::Struct package
        name that the record should be unpacked into when loaded.  These are
        packages like SpamReport::Email , SpamReport::Email::Bounce , etc.

    YYYY-MD-DD.stor - a Storable file containing metadata from the given date.
        These are mostly counters, many of them not reproducible from the
        associated preparsed logs.  preparse merges all of these counters
        together to know, for example, the total number of outgoing emails for
        a time period.

    spamperformance.log - keeps one-line log entries of how performant
        spamreport runs are.  spamreport removes old entries from this file to
        ensure that it doesn't grow too large.

    spamscripts.dat - YAML file mapping md5sums -> day (@midnight) -> ip, path
        counts.  As md5sums take quite a long time, they're only gathered on
        --cron runs and they're gathered by a background process that does
        nothing but perform the md5sums and update this file.  Old md5sums are
        rotated out of the file independently of normal log rotation.
